---
title: 'The UK Biobank Study: Systematic Review of the Reporting Quality in UK Biobank
  Studies'
author: Emma Anderson, George Davey Smith, Katie Drax, Mark Gibson, Marcus Munaf√≤, Robert Thibault, Benjamin Woolf, and Rebecca Richmond
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  word_document:
    number_sections: yes
  html_document:
    df_print: paged
  pdf_document: default
csl: apa.csl
bibliography: manuscript.bib
---

```{r setup, include=FALSE, echo=F}
knitr::opts_chunk$set(echo = F)

############
# libraries ####
#############
library(magrittr)
library(ggplot2)
library(tableone)
library(gtools)
library(tidyr)
library(RColorBrewer)
library(dplyr)
library(irr)
library(lpSolve)
library(pander)

######################
# import  ####
######################


# save naming convention used for strobe item variables as a pattern to be used in grep

strobe_pattern <- "^s[[:digit:]]{1,2}"

import_recoded <- function(){
  # most variables are unordered factors (nominal with set responses) so read in with stringsAsFactors = T
  df_orig <- read.csv("../outputs/data-extraction-form-clean.csv", encoding = "UTF-8", na.strings = c(""), stringsAsFactors = T)
  df <- df_orig
  for(i in colnames(df)){
    # remove - from "Partially-External" as R doesn't like punctuation in factor levels
    x <- gsub("Partially-External", "PartiallyExternal", df[[i]]) %>%
      # make not applicable lowercase so doesn't clash with missing (NA) notation
      gsub("NA", "na", .) %>%
      # convert back into factor as gsub will have converted it to character
      as.factor(.)
    # check removed
    if(length(which(x == "Partially-External") != 0)) stop("some Partially-External remain in ", i)
    if(length(which(x =="NA") != 0)) stop("some not applicable values remain in ", i)
    df[[i]] <- x
  }
  return(df)
}

df <- import_recoded()

###################
# add presence cols ####
#####################

# add non-strobe cols indicating if non-strobe items present

add_pres <- function(df){
  df$ukb_app_pres <- !is.na(df$ukb_app)
  df$email_pres <- !is.na(df$email)
  df$keywords_pres <- !is.na(df$keywords)
  df$coi_pres <- !is.na(df$coi)
  # drop cols just created presence cols for as no longer needed for frequencies
  df <- df[, -which(colnames(df) %in% c("ukb_app", "email", "keywords", "coi"))]
  return(df)
}

df <- add_pres(df)

############
# drop non-strobe cols ####
#############

drop_cols <- function(){
  # remove predict col as df only contains non-prediction papers
  if(!any(df$predict == "Yes", na.rm = T)){
    df$predict <- NULL
  }else{
    stop("predict col not empty")
  }
  # drop access_article as this should be all yes
  if(all(df$access_article == "Yes")){
    df$access_article <- NULL
  } else {
    stop("access_article not just yes")
  }
  # save names of cols not needed 
  void <- grep("title|comments\\.", colnames(df), value = T)
  if(!all(void %in% colnames(df))) stop("df doesn't have ", void[!void %in% colnames(df)])
  # drop not needed cols by name
  df <- df[, -which(colnames(df) %in% void)]
}

df <- drop_cols()

# vector of original column names for checking later

if(sum(duplicated(colnames(df))) == 0){
  df_cols <- colnames(df)
} else {
  stop("duplicated col names")
}

########################
# save vector of strobe cols ####
########################

strobe_cols_names <- grep(strobe_pattern, colnames(df), value =T)

strobe_stem <- gsub("_.*", "", strobe_cols_names) %>%
  unique()
###################################
# split into strobe and non-strobe ####
#################################


# create funciton to check strobe items named & positioned correctly
check_strobe <- function(df){
  # find all strobe cols
  strobe_cols_positions <- which(colnames(df) %in% strobe_cols_names)
  # vector of numbers in strobe col names
  strobe_nums <- strobe_cols_names %>%
    # remove all punctuation and letters
    gsub("[[:punct:]]|[[:alpha:]]", "", .)%>%
    # remove duplicates
    unique()
  
  # check all strobe_nums are in 1-22
  if(!identical(unique(gsub("[[:alpha:]]", "", strobe_nums)), as.character(c(1:22)))){
    df <- NULL
    warning("strobe_nums don't equal 1-22")
  } 
  if(sum(duplicated(strobe_nums)) != 0){
    df <- NULL
    warning("duplicate strobe_nums")
  } 
  # check positions of strobe items are sequential (i.e. all positions have a diff of 1 between them)
  if(!all(abs(diff(strobe_cols_positions)) == 1)){
    df <- NULL
    warning("strobe items are not in sequential in df")
  } 
  return(df)
}

df <- check_strobe(df)

# if passes strobe check, separate df into strobe items and non-strobe items

s_df <- df[, which(colnames(df) %in% c("article_id", strobe_cols_names))]
not_s_df <- df[, -which(colnames(df) %in% strobe_cols_names)]

# check total ncol of s_df and not_s_df is same as original df +1 because article_id col is in both
if(ncol(s_df) + ncol(not_s_df) != ncol(df) +1) stop("wrong number of cols in strobe or not_strobe dfs")

#########################
# recode strobe factors ####
########################

# recode strobe variables into factors so can analyse later
factorise_strobe <- function(){
  # check strobe cols correct
  if(!all(strobe_cols_names %in% colnames(s_df))) stop("some strobe cols not in s_df")
  # save s_df before recoding factors
  pre_recode <- s_df
  # recode all strobe cols in s_df
  for(i in strobe_cols_names){
    # set all cols to factor
    s_df[[i]] <- as.factor(s_df[[i]])
    #recode all factor levels
    levels(s_df[[i]]) <- list(Yes = "Yes", PartiallyExternal = "PartiallyExternal", Partially = "Partially", No = "No", na = "na")
  }
  
  # check recode successful
  
  x <- c()
  
  for(i in strobe_cols_names){
    y <- all.equal(as.character(s_df[[i]]), as.character(pre_recode[[i]]))
    x <- c(x, y)
  }
  # check all cols identical as they were before recoding
  if(sum(x) != length(x) | length(x) == 0) stop("factor recoded cols in s_df are different to before recoding")
  # check factors created
  classes <- sapply(s_df, class)
  if(!any(classes == "factor")) stop("no factors created")
  return(s_df)
}

s_df <- factorise_strobe()


#######################
# divide strobe into ternary ####
########################

recode_strobe <- function(style = c("binary", "ternary")){
  # check style arg correct
  if(!style %in% c("binary", "ternary")) stop("style arg incorrect")
  
  # recode s_df
  x <- s_df
  
  # convert all cols into character variables
  x[] <- lapply(x, as.character)
  
  # get ids of all strobe cols
  id <- grep(strobe_pattern, colnames(x)) 
  
  # check all are characters
  for(i in id){
    if(is.character(x[, i]) == F) stop(i, "isn't a character")
  }
  # recode into binary
  if(style == "binary"){
    for(i in id){
      x[, i] <-  gsub("^Yes$", "1", x[, i]) %>%
        gsub("^No$|^Partially$|^PartiallyExternal$", "0", .) %>%
        gsub("na", NA, .) %>%
        as.numeric(.)
      if(is.numeric(x[, i]) == F) stop(i, "not numeric")
    }
  }
  # recode into ternary
  if(style == "ternary") {
    for(i in id){
      x[, i] <-  gsub("^Yes$|^PartiallyExternal$", "1", x[, i]) %>%
        gsub("^Partially$", "0.5", .) %>%
        gsub("^No$", "0", .) %>%
        gsub("na", NA, .) %>%
        as.numeric(.)
      if(is.numeric(x[, i]) == F) stop(i, "not numeric")
    }
  }
  #check strobe cols
  if(!all(strobe_cols_names %in% colnames(x))) stop("some strobe cols not in s_df_tri")
  
  return(x)
}

s_df_bin <- recode_strobe(style = "binary")
s_df_tri <- recode_strobe(style = "ternary")

#######################
# calculate strobe scores for ternary  ####
######################## 


sum_items <- function(df, style = c("binary", "ternary")){
  # check style arg correct
  if(!style %in% c("binary", "ternary")) stop("style arg incorrect")
  
  pre <- ncol(df)
  for(i in strobe_stem){
    # convert stem into pattern so don't get greedy matches e.g. s2 match s22
    pat <- paste0(c(paste0(i, "_"), paste0(i, "$")), collapse = "|")
    # save dataframe of variables for same strobe item so can sum rows
    x <- df[, grep(pat, colnames(df))]
    # create sum col name
    sum_name <- paste(i, "sum", sep = "_")
    # sum rows in x if it is a dataframe 
    if(!is.numeric(x)){
      sum_var <- rowSums(x, na.rm = T) / rowSums(!is.na(x))
    } else {
      # if not dataframe then no need to sum rows because only 1 col
      sum_var <- x
    }
    # check no rows dropped during summing
    if(length(sum_var) != nrow(df)) stop("missing some assessments")
    # make scores binary or ternary 
    if(style == "binary"){
      # force into binary by rounding down any less than 1 to indicate all yes/not yes
      sum_var[sum_var < 1] <- 0
    }
    if(style == "ternary"){
      # force into ternary by rounding any not 0 or 1 numbers to 0.5 to indicate partialness
      sum_var[sum_var >0 & sum_var < 1] <- 0.5
    }
    # add sum to df under sum_name
    df[[sum_name]] <- sum_var
  }
  
  
  if(ncol(df) != pre + length(unique(strobe_stem)))
    stop("cols don't equal number of n cols before function plus number strobe items")
  
  # drop all columns that are not summs composite strobe items and strobe items without subdivisions
  df <- df[, which(colnames(df) %in% c("article_id", grep("_sum$", colnames(df), value = T)))]
  
  # remove NaN values because rowSums will have introduced them
  is.nan.data.frame <- function(x)
    do.call(cbind, lapply(x, is.nan))
  
  df[is.nan(df)] <- NA
  
  # remove _sum from all colnames so matches strobe stems
  colnames(df) <- gsub("_.*", "", colnames(df))
  
  return(df)
}

tri_sum <- sum_items(s_df_tri, style = "ternary")
bin_sum <- sum_items(s_df_bin, style = "binary")



#####################
# create bar chart data ###
#######################

create_bar_data <- function(df){
  bar_data <- df[, which(colnames(df) %in% strobe_stem)]
  if(ncol(bar_data) != length(strobe_stem)) stop("some strobe items missing")
  # clean col names so will match names of strobe items in strobe guidance
  colnames(bar_data) <- colnames(bar_data) %>%
    gsub("^s|__sum|starred", "", .) 
  
  # change all to character to create table one
  bar_data[] <- lapply(bar_data, as.character)
  
  bar_data <- tidyr::pivot_longer(bar_data, colnames(bar_data), names_to = "strobe_item", values_to = "value") 
  x <- table(bar_data$strobe_item, bar_data$value, useNA = "always") %>%
    # convert to dataframe
    as.data.frame.matrix()
  y <- prop.table(table(bar_data$strobe_item, bar_data$value), 1) %>%
    # round so more interpretable
    round(., 2) %>%
    as.data.frame.matrix()

  # row names will contain the x values given to table(x, y), move these to a column >
  # remove the X added
  x$strobe_item <- gsub("^X", "", row.names(x))
  row.names(x) <- NULL
  
  y$strobe_item <- gsub("^X", "", row.names(y))
  row.names(y) <- NULL
  
  # useNA in x means there will be an blank column name for the NA values, rename this as won't pivot if any missing
  colnames(x)[is.na(colnames(x))] <- "na"
  # useNA also creates an "NA" row, remove this
  x <- x[-grep("NA", x$strobe_item), ]
  
  # save response cols so can pivot them
  x_cols <- colnames(x)[-which(colnames(x) %in% "strobe_item")]
  
  # create response column
  x <- pivot_longer(x, all_of(x_cols), names_to = "response", values_to = "count")
  
  # save response cols so can pivot them
  y_cols <- colnames(y)[-which(colnames(y) %in% "strobe_item")]
  
  # create response column
  y <- pivot_longer(y, all_of(y_cols), names_to = "response", values_to = "percent")
  
  # check strobe items identical so will merge properly
  if(!identical(unique(x$strobe_item), unique(y$strobe_item))) stop("x and y strobe items different")
  
  bar_data <- full_join(x, y, by = c("strobe_item", "response"), suffix = c(".count", ".percent"))
  
  # reorder
  bar_data <- bar_data[mixedorder(as.character(bar_data$strobe_item)),]
  
  return(bar_data)
}

bar_data <- create_bar_data(tri_sum)

#############################
# export data to create bar chart labels ####
##########################

create_bar_labels_csv <- function(){
  strobe_qs <- read.csv("../outputs/extraction_dict.csv", stringsAsFactors = F, encoding = "UTF-8") %>%
    .[, colnames(.) %in% c("question", "variable")] %>%
    # select those that are strobe items 
    .[grep(strobe_pattern, .$variable), ] %>%
    .[-grep("\\_ev|\\_star", .$variable), ]
  
  strobe_qs$question <- sub("[^0-9]*", "", strobe_qs$question)
  strobe_qs$strobe_item <- sub("\\_.*", "", strobe_qs$variable)
  write.csv(strobe_qs, "../outputs/bar_labels.csv", row.names = F, fileEncoding = "UTF-8")
}

create_bar_labels_csv()

##############
## MANUAL ####
############

# MANUALLY INSTRUCTIONS
# added text describing the strobe item the bar_labels.csv

###########################
# import labels and clean ####
########################


create_labels <- function(){
  
  # import general as these contain labels at the strobe item level (not design specific)
  labels <- read.csv("../data/bar_labels.csv", encoding = "UTF-8", stringsAsFactors = F, na.strings = "") %>%
    .[, colnames(.) %in% c("variable", "item_level_label")]
  
  # clean variable names so matches bar_chart_freq colnames (i.e. no subdivisions and no design specific questions) >
  # easiest to do this by cleaning non-cohort specific quesitons first then cohort excluding 14c_coh since this contains no roman numerials and is not a sub division
  labels$variable <- gsub("_.*|starred|s", "", labels$variable)

  # remove duplicated rows now variables cleaned
  labels <- labels[!duplicated(labels),]
  # sort
  labels <- labels[mixedorder(as.character(labels$variable)),]
  
  # select applic col so can merge in
  applic_df <- bar_data[bar_data$response == "na", which(colnames(bar_data) %in% c("strobe_item", "count"))]
  
  # add applic col to labels rows only so can remove empty labels that are empty and wont appear in bar chart
  labels <- left_join(labels, applic_df, by = c("variable" = "strobe_item"))
  
  # add number of applicable items to labels so can see how many items were relevant in bar
  if(identical(labels$variable, 
               as.character(unique(bar_data$strobe_item)))){
    # paste variable together with description , separate by space so can gsub later
    labels$x_labels <- paste(labels$variable, labels$item_level_label, sep = " ") %>%
      # order
      .[gtools::mixedorder(.)]%>%
      # wrap
      stringr::str_wrap(., width = 55) %>%
      # add n = applicable on a newline
      paste(., " (n=", nrow(df) - labels$count, ")", sep = "")
  } else {
    stop("not identical")
  }
  return(labels)
}

labels <- create_labels()


#######################
## bar chart for all ####
##################
strobe_levels <-  bar_data$strobe_item[!duplicated(bar_data$strobe_item)]
# set levels as mixed order so order preserved in ggplot
bar_data$strobe_item<- factor(bar_data$strobe_item, levels = 
                                strobe_levels[gtools::mixedorder(strobe_levels)])

bar_data$response <- as.factor(bar_data$response)

# set levels using list so is accurate
levels(bar_data$response) <- list(NotApplicable = "na", No = 0, Partially = 0.5, Yes = 1)

# add space to NA level since can't do this in list
levels(bar_data$response)[levels(bar_data$response) == "NotApplicable"] <- "Not Applicable"

# check labels identical to strobe item numbers in labels$x_labels (gsub at the space) to ensure labels will map to chart
if(!identical(gsub(" .*", "", labels$x_labels), as.character(strobe_levels))) stop("labels won't map")

png("Rplot9.png", width = 1300, height = 1500)

# strobe item on x axis and plot % yes
bar_data %>%ggplot(aes(x=strobe_item, y=count, fill = response)) + 
  # blue fill
  geom_bar(stat="identity") +
  theme_classic() +
  theme(text = element_text(size=30))+
  scale_x_discrete(labels= labels$x_labels) +
  scale_y_continuous(breaks = seq(0, nrow(df), by = 10)) + 
  coord_flip() +
  xlab("STROBE Item") +
  ylab("Count") +
  scale_fill_brewer(palette = "Greys") +
  #geom_text(aes(label = count), vjust = 0, size = 8) +
  theme(plot.title = element_text(size = 22)) 
dev.off()


#####################
# calculate irr for NA and applicable ####
################################

inter <- read.csv("../outputs/data-extraction-form-conflicted.csv", na.strings = "")

create_kappa_df <- function(df){
  
  # save stems of variables that were not double coded (and therefore not conflicted)
  # kd alone extracted some variables so save all these variables single/unique variables
  single <- c("email","country","ukb_app","keywords","coi", "article_id") %>%
    #  qualtrics metadata, comments & title substring vars are unique to each coder so stems duplicated but not colnames >
    c(., "distribution_channel", "duration_in_seconds", "end_date", "finished", "progress", "recorded_date", "response_id", "response_type", "start_date", "user_language") %>%
    # remove those unique to each coder
    c(., "comments", "title_clean", "title_sub", "title")
  
  stem <- grep("\\.", colnames(df), value = T) %>%
    gsub("\\..*", "", .) %>%
    unique() %>%
    # remove single coded items since these can't be conflicted
    .[!. %in% single] %>%
    # remove predict because we already resolved these conflicts
    .[!. %in% "predict"] %>%
    # remove other variables that are not discrete
    .[!. %in% c("other_guidelines", "reg_id")] %>%
    # add '.' onto end so will match full word
    paste0(., "\\.")
  
  # save stems of duplicate and not applicable cols so can join back in
  na_items <- c("5_vi", "6a_iii", "10", "8starred_iii")
  na_stem <-  grep(paste0(na_items, collapse ="|"), stem, value =T)
  
  # find other empty rows and add them to the na_stems
  for(i in stem){
    x <- df[, grep(i, colnames(df))]
    i_na <- sum(is.na(x[[1]] != x[[2]]))
    if(i_na == nrow(df)){
      na_stem <- c(na_stem, i)
    }
  }
  
  # keep only unique so not creating duplicates when add back in
  na_stem <- unique(na_stem)
  
  # remove all stems that are duplicate or not applicable as will throw error in kappa2 if set "NA" to missing and all are set to NA after qualtrics
  
  stem <- stem[-which(stem %in% na_stem)]
  #save empty objects so can save outputs from for loop
  kappa <- c()
  z <- c()
  variable <- c()
  n_match <- c()
  agree <-c()
  n_na <- c()
  
  for(i in stem){
    x <- df[, grep(i, colnames(df))]
    y <- kappa2(x, weight = "unweighted")
    variable <- c(variable, i)
    kappa <- c(kappa, y$value)
    z <- c(z, y$statistic)
    i_match <- sum(x[[1]] == x[[2]], na.rm = T)
    n_match <- c(n_match, i_match)
    # count number of items with NA--NA dyads or notNA--NA dyads so are excluded from kappa
    i_na <- sum(is.na(x[[1]] != x[[2]]))
    n_na <- c(n_na, i_na)
    app <- sum(!is.na(x[[1]] != x[[2]]))
    i_agree <- round((i_match / app) * 100, 0)
    agree <- c(agree, i_agree)
  }
  
  # bind objects into df so can render in manuscript
  irr_df <- data.frame(STROBEItem = variable, Kappa = kappa, Zstatistic = z, Matches = n_match, Agreement = agree, NotApplicableUnsure = n_na)
  
  # create df of empty varibles and bind to main df so will appear in table
  empty <- data.frame(STROBEItem = na_stem)
  irr_df <- full_join(irr_df, empty, by = "STROBEItem")
  
  # round all numeric cols so more interpretable
  nums <- colnames(irr_df)[colnames(irr_df) != "STROBEItem"]
  for(i in nums){
    x <- irr_df[[i]]
    if(!is.numeric(x)) stop(i, " col not numeric")
    x <- round(x, digits = 2)
    irr_df[[i]] <- x
  }
  
  # remove backslash that was added to variable names
  irr_df$STROBEItem <- gsub("\\\\.*", "", irr_df$STROBEItem)
  
  # reorder
  irr_df <- irr_df[gtools::mixedorder(irr_df$STROBEItem), ] 
  
  irr_df$STROBEItem <- as.factor(irr_df$STROBEItem)
  # set rownames to null to ensure none created
  row.names(irr_df) <- NULL
  
  return(irr_df)
}

##########################
# kappa for applicability #####
##########################

# divide df into into NA and applicable

divide_na <- function(){
  for(i in colnames(inter)){
    x <- inter[[i]]
    x[x != "NA"] <- "A"
    inter[[i]] <- x
  }
  return(inter)
}

inter_na <- divide_na()
kappa_na <- create_kappa_df(inter_na)

#######################
# calculate strobe scores for inter at subdivision level  ####
######################## 

inter_sub <- inter
inter_sub[inter_sub == "NA" | inter_sub == "Unsure"] <- NA
inter_sub[inter_sub == "Partially-External"] <- "Yes"

# only select 
inter_sub <- inter_sub[, grep(strobe_pattern, colnames(inter_sub))]
kappa_sub <- create_kappa_df(inter_sub)

#######################
# calculate strobe scores for ternary for inter  ####
######################## 

# split into kd and coder2 so can sum strobe items for each then rejoin
kd <- inter[, c("article_id", grep("\\.kd", colnames(inter), value = T))]
coder2 <- inter[, c("article_id", grep("\\.coder2", colnames(inter), value = T))]

sum_items <- function(df, coder_suffix){
  # set "NA" and "Unsure" as missing so calculations only apply to reporting judgements
  df[df == "NA" | df == "Unsure"] <- NA
  strobe_cols_names <- grep(strobe_pattern, colnames(df), value =T)
  
  # remove everything after _ or suffix
  strobe_stem <- gsub("_.*|\\..*", "", strobe_cols_names) %>%
    unique()
  
  pre <- ncol(df)
  
  for(i in strobe_stem){
    # convert stem into pattern so don't get greedy matches e.g. s2 match s22
    pat <- paste0(c(paste0(i, "_"), paste0(i, "$"), paste0(i, "\\.")), collapse = "|")
    # save dataframe of variables for same strobe item so can sum rows
    x <- df[,grep(pat, colnames(df))]
    # create sum col name
    sum_name <- paste0(i, "_sum", coder_suffix)
    # create empty sum_var to add values to in for loop
    sum_var <- c()
    # sum rows in x if it is a dataframe 
    if(is.data.frame(x)){
      for(j in 1:nrow(x)){
        row <- as.character(x[j, ])[!is.na(as.character(x[j, ]))]
        if(length(row) == 0) {
          sum_var[j] <- NA
        } else {
          if(all(row %in% c("Yes", "Partially-External"), na.rm = T)) {
            sum_var[j] <- "Yes"
          } else {
            if(!all(row %in% c("Yes", "Partially-External"), na.rm = T) & !all(row == "No", na.rm = T)) {
              sum_var[j] <- "Partially"
            } else {
              if(all(row == "No", na.rm = T)) {
                sum_var[j] <- "No"
              } else {
                stop(j, " in ", i, " doesn't contain just yes, pe, partially or no")
              }
            }
          }
        }
      }
    } else {
      # if not dataframe then no need to sum rows because only 1 col
      sum_var <- x
    }
    # check no rows dropped during summing
    if(length(sum_var) != nrow(df)) stop("missing some assessments")
    # add sum to df under sum_name
    df[[sum_name]] <- sum_var
  }
  if(ncol(df) != pre + length(unique(strobe_stem)))
    stop("cols don't equal number of n cols before function plus number strobe items")
  
  # drop all cols that are not strobe sums & article id so can merge on id
  df <- df[, which(colnames(df) %in% c("article_id", grep("_sum", colnames(df), value =T)))]
  
  return(df)
}

kd <- sum_items(kd, ".kd")
coder2 <- sum_items(coder2, ".coder2")

inter_item <- full_join(kd, coder2, by = "article_id") %>%
  # reorder
  .[ , gtools::mixedorder(colnames(.))] %>%
  # remove article_id
  .[, -which(colnames(.) %in% "article_id")]

kappa_item <- create_kappa_df(inter_item)

kappa_item$STROBEItem <-   gsub("_sum|starred|^s", "", kappa_item$STROBEItem)

###################
# create table 2 - frequencies non-strobe ####
##################

# save version of not strobe df without qualtrics metadata variables to create table 2

create_table2 <- function(){
  # save pattern to find qualtrics variables
  qual <- c("distribution_channel", "duration_in_seconds", "end_date", "finished", "progress","recorded_date", "response_id", "response_type", "start_date", "user_language")
  qual_pat <- paste0("^", qual, ".", collapse = "|")
  
  # find qualtrics columns in df
  qual_cols <- grep(qual_pat, colnames(not_s_df))
  
  # check there are 4 of each qual column
  if(length(qual_cols) != 4* length(qual)) stop("some qualtrics cols missing")
  
  table2 <- not_s_df[, -qual_cols]
  
  # drop cols that are qualitative so contain unique info for each observation so no point in calculating frequencies
  table2 <- table2[, -which(colnames(table2) %in% c("article_id", "correction_address", "open_access_address", "reg_id", "correction_address"))]
  
  #convert all non-strobe cols into characters as easier than setting multiple different factor levels
  for(i in colnames(table2)){
    table2[[i]] <- as.character(table2[[i]])
  }
  
  # ensure UK and USA country values are capitalised as frequency is case-sensitive
  uk_usa <- grep("^uk$|^usa$", table2$country, ignore.case = T)
  table2$country[uk_usa] <- toupper(table2$country[uk_usa])
  
  # drop cols that are characteristics
  chars <- c("designs", "country", "year")
  if(!all(chars %in% colnames(table2))) stop("missing char elements in colnames")
  table2 <- table2[, -which(colnames(table2) %in% chars)]
  
  # set missing & na as won't make a difference to absolute numbers
  table2[is.na(table2)|table2 == "na"] <- "Not Applicable"
  table2[table2 == "ni"] <- "No information"
  table2[table2 == "TRUE"] <- "Yes"
  table2[table2 == "FALSE"] <- "No"
  
  # replace unclear value to make it more understandable
  table2[table2 == "No available elsewhere"] <- "No but publicly available on another platform"
  table2[table2 == "yes_exact"] <- "Yes - exact wording"
  table2[table2 == "yes_almost"] <- "Yes - almost exact wording"
  
  # rename table2 colnames so will come out as full words in createtableon
  colnames(table2)[colnames(table2) == "code"] <- "Report shared analysis code"
  colnames(table2)[colnames(table2) == "exposure"] <- "Exposure variables clearly labelled as exposures"
  colnames(table2)[colnames(table2) == "outcome"] <- "Outcome variables clearly labeled as outcomes"
  colnames(table2)[colnames(table2) == "reg"] <- "Report analyses registered"
  colnames(table2)[colnames(table2) == "strobe"] <- "Report using STROBE guidelines"
  colnames(table2)[colnames(table2) == "strobe_cite"] <- "Cite STROBE guidelines if used"
  colnames(table2)[colnames(table2) == "ukb_credit"] <- "Report UK Biobank credit statement correctly"
  colnames(table2)[colnames(table2) == "var_id"] <- "Report UK Biobank variable IDs"
  colnames(table2)[colnames(table2) == "other_guidelines"] <- "Report using reporting guidelines other than STROBE"
  colnames(table2)[colnames(table2) == "open_access_publisher"] <- "Published as open access"
  colnames(table2)[colnames(table2) == "correction"] <- "Has a correction"
  colnames(table2)[colnames(table2) == "ukb_app_pres"] <- "Report UK Biobank application number" 
  colnames(table2)[colnames(table2) == "email_pres"] <- "Has email address for corresponding author"
  colnames(table2)[colnames(table2) == "keywords_pres"] <- "Has keywords"
  colnames(table2)[colnames(table2) == "coi_pres"] <- "Report conflict of interest statement"
  colnames(table2)[colnames(table2) == "access_supp"] <- "Has supplementary material"
  
# drop retraction col because none should be
  table2 <- table2[, -which(colnames(table2) %in% "retraction")]
  return(table2)
}


table2 <- create_table2()



CreateTableOne(data = table2, includeNA = F) %>%
  print(., noSpaces = T) %>%
  write.csv(., "../outputs/table2.csv")

#############
# create stab2####
############


# create labels for strobe items at subdivision level

sub_labels <- read.csv("../outputs/extraction_dict.csv", stringsAsFactors = F, encoding = "UTF-8") %>%
  .[grep(strobe_pattern, .$variable), ] %>%
  .[-grep("_ev$", .$variable),]

# create stabe

create_stab2 <- function(){
  stab2 <- df[, which(colnames(df) %in% c(strobe_cols_names))]
  # convert all to characters so can easily reset values and table will just treat as nominal
  for(i in colnames(stab2)){
    stab2[[i]] <- as.character(stab2[[i]])
  }
  
  # set missing to na as won't make a difference to absolute numbers
  stab2[is.na(stab2)|stab2 == "na"] <- "Not Applicable"
  stab2[stab2 == "PartiallyExternal"] <- "Yes"
  
  
  # pivot so can table frequencies
  stab2 <- tidyr::pivot_longer(stab2, colnames(stab2), names_to = "strobe_item", values_to = "value") %>%
    # reorder so follows strobe order
    .[mixedorder(as.character(.$strobe_item)), ]
  
  strobe_levels <-  unique(stab2$strobe_item)
  
  # set levels as mixed order so order preserved in ggplot and pander
  stab2$strobe_item<- factor(stab2$strobe_item, levels =  strobe_levels[gtools::mixedorder(strobe_levels)])
  
  
  # order levels 
  stab2$value <- as.factor(stab2$value)
  levels(stab2$value) <- list(NotApplicable = "Not Applicable", No = "No", Partially = "Partially", Yes = "Yes")
  
  return(stab2)
}

labels <-  read.csv("../outputs/extraction_dict.csv", encoding = "UTF-8", na.strings = c(""), stringsAsFactors = T)

stab2 <- create_stab2()
stab2_tab <- table(stab2$strobe_item, stab2$value, useNA = "ifany") 

stab2 <- left_join(stab2, labels, by = c("strobe_item" = "variable"))

stab2$question <- gsub("Indicate if the authors report the following items for all the studies in the article \\(unless a study design is specified\\) - |Indicate if the authors report the following items for all the cross-sectional studies in the article - |_ - |Indicate if the authors report the following items for all the case-control studies in the article - |Indicate if the authors report the following items for all the cohort studies in the article - |Indicate if the authors report the following items for all the cross-sectional and cohort studies in the article - ", "", stab2$question)

png("Rplot10.png", width = 1300, height = 1500)

# strobe item on x axis and plot % yes
stab2 %>%ggplot(aes(x=strobe_item, y=..count.., fill = value)) + 
  # blue fill
  geom_bar() +
  theme_classic() +
  theme(text = element_text(size=30))+
 # scale_x_discrete(labels= unique(stab2$question)) +
  #scale_y_continuous(breaks = seq(0, nrow(df), by = 10)) + 
  coord_flip() +
  xlab("STROBE Item") +
  ylab("Count") +
  scale_fill_brewer(palette = "Greys") +
  #geom_text(aes(label = count), vjust = 0, size = 8) +
  theme(plot.title = element_text(size = 22)) 
dev.off()


```

``` {r}
# Abstract
#
#Background
#
#The STrengthening the Reporting of OBservational studies in #Epidemiology (STROBE)
#statement provides a reporting guideline for observational #studies, including secondary analyses.
#We used the STROBE guidelines to assess the reporting quality #of studies using UK Biobank data.
#
#Participants
#
#We assessed 70 cohort, cross-sectional and case-control #studies published before 2019 using the STROBE guidelines.
#
#Results
#We identified ??? studies, included ???, and assessed a #random sample of ???.
#
#Conclusions
```


```{r, prisma}

# 4. questions picos


```

# Background

There is a general move towards making data freely accessible, or ‚Äòopen‚Äô, by academic and governmental institutions alike [@vasilevsky2017; @worldwidewebfoundation2018]. 
Completely open data allows any individual, regardless of their motivation, discipline or skillset, to access and analyse a dataset for free. 
This accessibility offers researchers new opportunities but there is also uncertainty about how the nature of open data may impact the reliability of research findings. 
One method researchers can use to investigate the reliability of results from open data is replication.
In the case of secondary data analyses replications will involve new researchers retrieving the same dataset as the previous researchers and repeating their analyses.
Researchers can make such direct replications of their work easier by publishing a detailed description of their statistical analysis.
However, recent evidence suggests that it is unclear whether a detailed plan alone is sufficient to ensure direct replicability of findings [@hardwicke2018; @naudet2018]. 

To investigate the reliability of findings from open data, we will attempt to replicate all eligible research articles that use UK Biobank (UKB) data. 
The UKB is a prospective cohort study which collected a wide range of health data from 500,000 people aged 40-69 in the UK during 2006-2010 [@ukbiobankcoordinatingcentre2007].
Importantly, UKB data is "controlled data", meaning it is only available to bona fide researchers conducting research in the public interest on a cost-recovery basis.
The UKB reserves the right to reject access applications for projects it deems inappropriate [@ukbiobankcoordinatingcentre2011].
We plan to replicate UKB studies specifically because there is an abundance of published articles using the data and they are all contemporary, which increases the likelihood that authors will be contactable.
Furthermore, they all use the same, professionally collected, maintained and diverse open resource which we will be able to access and use.

We first conducted a systematic review to (1) assess the completeness of UKB study reporting, (2) identify articles that are suitable for replication, and (3) inform the development of reporting guidelines for other articles using the UKB and similar resources. 
Many previous systematic reviews of reporting quality across a range of disciplines used guidelines to assess the completeness of reporting [e.g. @agha2014; @cook2011; @plint2006).
We used the STROBE (STrengthening the Reporting of Observational Studies in Epidemiology) Statement, which provides reporting guidelines for observational studies, to evaluate articles arising from UKB and to make comparisons between the articles. 
The STROBE Statement has been endorsed by over 100 journals and, as no major changes have been made to the original version published in 2007 [@cevallos2014], these guidelines are relevant to all studies conducted using the UKB.
Given that studies conducted using UKB may be cohort, cross-sectional or ‚Äònested‚Äô case-control, the review used the combined STROBE Statement for cohort, cross-sectional and case-control designs, and its extensions, to assess the reporting quality in UKB articles.

We conducted a systematic review of articles reporting studies using data from the UKB with the aim of answering the following questions:

1. What is the quality of reporting of findings from the UKB (in terms of the detail, clarity and completeness with which authors report their design, analysis and results)?
2. Does reporting quality vary across the type of studies conducted?

# Methods

## Protocol registration

This study was preregistered before we began to screen the search results [@drax2019].
For a description of the deviations from the registered protocol see the Supplementary Material.

## Inclusion criteria

The inclusion criteria were:

* Publication date: After 30 March 2012. 
This is the date the UKB was launched and UKB data was first available for researchers to use.
* Publication type: Full research articles (including simulation and modelling articles).
* Language: English. 
Relevant studies written in another language may be relevant but, to ensure accurate and precise evaluation, the article would require a professional translation which is not feasible given the review‚Äôs resources.
* Data source: Article‚Äôs findings were produced from analysis(es) of data from the UKB. 
This includes studies which reported findings from other studies alongside findings from UKB data.
* Study type: Observational epidemiology studies
* Study design: Cross-sectional, cohort, or case-control study design.

The exclusion criteria were:

* Article findings were produced from analysis(es) of pooled data from multiple studies.
These are studies which have used data from participants from the UKB and other datasets in the same analysis.
* Meta-analyses; narrative and systematic reviews; preprints; post-prints; replies; letters to the editor; corrections; and any other publication types that are not full research articles.
* Retracted articles
* Studies with inaccessible supplementary material. 
This was to ensure our estimates of reporting completeness included the entire version of record.


## Information sources and search strategy

We searched four databases on 15/01/2019 for UKB articles: PubMed, EMBASE, Web of Science Core Collection (WoSCC) and PsycINFO. 
The search strategy was limited to articles published from 2012 onwards and there was no restriction on language or publication type.

The full search strategy for each database is included in Appendix A of the protocol [@drax2019]. 
To summarise, the terms "UK Biobank", "UKB", "UKBiobank", and "UKB Resource" were included in the "Title", "Abstract", "Keywords", and "All Fields" fields or equivalent of each database.


```{r}
# is there counts for the number of articles from th eUKB list? 


```

## Study selection

We conducted three stages of screening for eligibility.
First, using Endnote, KD removed duplicate results, checked the results for completeness, updated the metadata if necessary, and retrieved the full-texts of all articles.
KD updated the metadata by checking each article's Endnote metadata contained the article's DOI, and adding them if they were missing.
KD checked completeness using a list of published full research articles that have used the UKB Resource, provided by the UKB on 27 November 2018. 
We conducted a systematic search despite having this list because we wished to capture all articles from 2018.
Using the full-texts of the results, KD assessed if results were full research articles, and excluded reviews, corrections, conference abstracts, etc.

Second, we imported the results into Rayyan [@ouzzani2016]. 
BW and KD independently screened the results and indicated if they met the inclusion criteria.
At this point we included all articles whether or not they had a cross-sectional, cohort, or case-control study design because the "Study design" inclusion critera was added later.
They examined full texts if inclusion was unclear from the abstract alone.
They discussed any conflicts and resolved them by mutual consent if possible, if not resolved after discussion then RR assigned the category.
If insufficient information was available in the full text to determine a paper‚Äôs eligibility, we contacted the authors and requested the required information, if it was unobtainable we excluded the article.
Time constraints meant we excluded XXX articles with insufficient information without contacting the authors.

## Data collection process

### Study Design Form

Different STROBE items are relevant for cohort, case-control and cross-sectional study designs. 
To ensure coders completed the same STROBE items for each article KD and MG independently identified the study designs used by each of the 178 ‚Äúobservational epidemiology‚Äù articles by completing the Study Design Form for each article.
In the form, coders also indicated if all supplementary material can be accessed via University of Bristol subscriptions. 
Any conflicts were discussed by the two coders and resolved by mutual consent if possible.
If not resolved after discussion, RR determined the study designs. 
The Study Design Form was hosted on Qualtrics but a PDF version can be found at https://osf.io/jfk24/.
During this process we also identified studies we did consider to be observational epidemiological studies but could not consider them to have cohort, case-control or cross-sectional designs - for example those using prediction models.
Any articles we could not classify as cohort, case-control, or cross-sectional were excluded at this point.

The articles were randomly assigned an ID number from 1-178.
We selected the articles with an ID number between 1 and 80 for the first round of data extraction. 
We assigned KD as the first coder for all 80 articles and randomly assigned MG, RR, or BW as the second coder.
We initially randomly selected 80 articles with the hope that we would randomly select more studies once data extraction for the first 80 were complete.
Unfortunately we did not have time to assess more studies so we do not have data on the remaining 98 articles. 
Figure 1 shows the flow of records identified from our searches and reasons for exclusion.

![Figure 1. Flow diagram of included articles](flow.png)

### Data Extraction Form

Two coders independently completed the data extraction form for each article assigned to them.
Almost all variables in the form were categorical so coders assigned the most appropriate category for each variable.
We conducted two pilots.
In the first, MG, KD and/or RR piloted 5 observational epidemiology articles.
We made major changes to the Data Extraction Form so we completed it again for the articles in the first pilot. 
In the second, KD piloted the changed form on 3 articles. 
We made no major changes so we kept the responses for articles in the second pilot.
The PDF version of the data extraction form contains full information on our variables and how we measured them and is available at https://osf.io/hngcj/.

The form contained questions to measure variables relating to the reporting quality of different information.
We derived some variables from the STROBE guidelines.
Some STROBE items were written as multiple-barrelled questions e.g " Report assessment methods for outcomes, exposures, predictors, confounder, and effect modifiers". 
We subdivided these questions into separate variables in the data extraction form.
We could have assessed each item without dividing it up but collecting the reporting completeness at the subdivision level we have a more granular understanding of what information is or is not reported.

Variables derived from the STROBE items had the same six categories:

* "NA = this information was not relevant to any of the studies in the article"
* "Unsure = I am unsure what to respond    "
* "No = this information was relevant but none of it was present"
* "Partially = some of the information was present"
* "Partially-External = some of the information was present and/or the authors report that additional information can be found in an external source (i.e. not in the article or supplementary material)" 
* "Yes = all of the information was present".

After two coders completed one data extraction form for each article, the two coders discussed any conflicts and resolved them by mutual consent if possible. 
If not resolved after discussion, RR resolved the conflict.
However, given the number of conflicts, this practice could not be sustained.
To reduce the time-burden on other authors KD and RR devised a series of "rules" and general guidelines KD could use to resolve conflicts by themself. 
This means KD resolved the majority of conflicts by these "Rules".
For example, for item 1a of the STROBE checklist we agreed that authors describing a study as a "longitudinal" is not sufficient according to the STROBE guidelines but it still gives some indication of the study design.
Therefore, we agreed on the rule "Rule = "Partially" if "longitudinal" referred to" for item 1a.
The rules and guidelines can be found at https://osf.io/hngcj/.

### Other data collection

The items in Table 2 were extracted manually by KD or automatically by Endnote which contained the article‚Äôs metadata exported from the database the article was located in.

### Unclear and Missing Information.

In our protocol we planned to locate and examine publications linked to the article, e.g. related full research articles, comments, corrections, etc, so that we could retrieve any missing items in the Data Extraction Form from them.
If the missing information is not contained in a linked publication we planned to contact the article‚Äôs authors.
However, we realised this would give an inaccurate assessment of the version of record. 
Also few articles had linked publications and there was a lot of missing or unclear information.
Therefore, we did not attempt to retrieve any missing items in the Data Extraction Form, from either the authors or linked articles. 

## Data analysis

Using the data extraction form on Qualtrics, we collected data on the reporting quality on numerous variables, including those derived from the STROBE items.
This mean our raw data estimated the reporting quality for all subdivisions of the STROBE items and for the ‚Äústarred‚Äù items associated with any STROBE items that had an asterisk (*) next to it. 
For the final analysis, we excluded all starred subdivisions because inter-rater reliability was so poor, this was primarily because raters could not agree when the items were or were not applicable.
In the data extraction form raters could indicate items as "NA", "Unsure", "No", "Partially", "Partially-External" or "Yes".
After resolving conflicts, no "Unsure" ratings remained. 
We collapsed the "Partially-External" into the "Yes" catergory.
This was because we agreed reporting there were very few "Partially-External" categories after resolving conflicts, to make the kappa statistics more interpretable, and we understood that reporting where the required information can be found could be considered complete reporting.
We summed the subdivisions back together to calculate the reporting completeness of each STROBE item they corresponded to. 
This gave us an understanding of the reporting quality for the entire STROBE item and reduced the number of variables from `r length(unique(stab2$strobe_item))` to `r length(unique(bar_data$strobe_item))`.

We calculated Cohen's kappa statistics to estimate the inter-rater reliability for each of the STROBE items.
We treated any "Not Applicable" or "Unsure" values as missing data in the kappa calculations.  
For our subgroup analyses we repeated the analyses for the subdivisions.
We conducted all our data cleaning and analysis in R.

# Results 

## Study characteristics

Of the `r nrow(df)` included articles `r sum(grepl("Case-control", df$designs))` contained case-control designs, `r sum(grepl("Cohort", df$designs))` cohort, and `r sum(grepl("Cross-sectional", df$designs))` cross-sectional. These numbers add up to more than 70 because some articles contained cross-sectional and cohort studies.
UK based researchers led the vast majority with `r sum(grepl("UK", df$country, ignore.case = F))` having authors affiliated with institutions in the UK.
The mean number of authors was `r round(mean(as.numeric(as.character(df$authors))))` (SD = `r round(sd(as.numeric(as.character(df$authors))))`).
`r sum(grepl("2014", df$year))` studies were published in 2014, `r sum(grepl("2015", df$year))` in 2015, `r sum(grepl("2016", df$year))` in 2016, `r sum(grepl("2017", df$year))` in 2017, `r sum(grepl("2018", df$year))` in 2018, and `r sum(grepl("2019", df$year))` in 2019.

## STROBE Reporting quality

Figure 1 presents the reporting completeness for each STROBE item, to ensure a comprehensive understanding of our results, Supplementary Figure 1 provides the reporting completeness for each subdivision.



![Figure 2. STROBE completion](Rplot9.png)

```{r to-do}

# CHECK OTHER STEMS ARE NOT BEING GREEDY
# REMOVE ACCOUNT FOR SAMPLING FROM 12D LABEL in figure 1?
```

Table 1 presents Cohen's kappa statistics for each of the STROBE items.
Many items had poor inter-rater reliability with `r sum(kappa_item$Kappa < 0.2 & kappa_item$Kappa != 0, na.rm = T)` items having a kappa below 0.2.
The main reason for this is that the data extraction form was subjective.
Conflicts occured when one coder did not notice that the required information was reported and when coders interpretted the STROBE item differently.
The list of "rules" we compiled give an indication for conflicts that occurred more than once, how we decided to resolve them and our justification for it.

```{r table1}

pander(kappa_item, caption = "Table 1. Inter-rater reliability for the STROBE items")

```


## Other reporting quality

We collected reporting quality data in addition to the STROBE items.
We intended to conduct exploratory analyses using these variables to answer our second research question, for example comparing articles that reported using some form of reporting guidelines to those who did not.
We did not conduct an exploratory analyses into the relationships between these variables because subgroup analyses for all of these variables would have very small subgroup samples. 
Instead we report the descriptive statistics for each variable in Table 2 below.

*Table 2. Descriptive statistics for additional reporting quality variables*

# Discussion

## Summary

Our results indicate that the STROBE items best reported by UK Biobank studies are those regarding backround (item 2), objectives (item 3), explaining design early (item 4), main statistical methods (item 12a), and summarising results (item 18) with nearly all articles reporting each item fully.
The good reporting of the main statistical methods is encouraging for the potential reproducibility of the analysis methods.
Most articles also fully reported information on generalisability (item 21).

Partial reporting dominated items regarding setting, recruitment, location, and dates (item 5); assessment methods (item 8); variable analysis and grouping (item 11); addressing missing data (item 12c); main results and definitions of confounders (item 16a); limitations and bias (item 19); and funder details (item 22). 
For some items partial reporting is not a major concern.
Although it does not meet the STROBE guidelines, all information for item 5 and 8 is fully reported in the publicly available UK Biobank documentation.
For others, partial reporting casts doubt on the ability of new researchers to know how to repeat the included studies. 
Authors rarely fully reported how they handled their variables (item 11) and missing data (item 12c).
Another potential area of concern is the reporting of sensitivity, subgroup, interaction, and other analyses.
Most reporting of the methods (items 12b and 12e) and results (item 17) from these analyses was incomplete. 
Both of these issues could limit how accurately the UK Biobank analysis methods can be repeated.

Other items that were poorly reported carry different concerns to those of reproducibility.
Most authors partially reported item 16a. 
Supplementary Figure 1 shows that while nearly all authors fully report their confounder-adjusted estimates most are failing report their unadjusted elements and to justify why they included the confounders they did.  
This information may be less vital to reproducing analyses than other items, but it does suggest a widespread norm of researchers including confounders without a stated justification.
Similarly the significant lack of reporting for item 9, 19 and 22 suggests it is acceptable for researchers not to provide detailed analysis of potential bias in their studies or report the role of funders in their studies.
Lastly, many authors failing to mention the design of their study in their title or abstract (item 1a) could create problems in retrieving studies during searches.

The worst reported items were 12d, 13c, 14b and 16c, with most authors reporting no information about them.
Again the implications are of varying concern for different items.
Figure 2 shows few authors reported addressing loss to follow up in item 12d.
This could be because many studies used NHS data linked to the UK Biobank as follow up data so the studies are likely to have low loss to follow up.
Although confirming this will require further investigation into the individual studies.
The impact of rare reporting of flow diagrams (item 13c) is also tempered by the good results for 13a and 13b, as it suggests authors do report the information just not in a flow diagram.
Authors are poor at reporting absolute risk estimates (16c) and missing data (14c).

We coded additional variables to measure reporting quality of information not covered by the STROBE guidelines.
62 articles reported a conflict of interest statement, 41 provided their studies' UK Biobank application number, and 59 reported the UK Biobank credit statement correctly.
However, the reporting was poor for the variables we included to assess the reproducibility of the analysis methods.
Only 2 papers shared any part of their analysis code, 2 reported having registered their analyses though whether these registrations were before or after seeing the data was unclear, and 10 reported at least one UK Biobank variable ID. 


## Limitations

Our study has several limitations.
Firstly, many variables in the data extraction form we used to assess reporting quality had poor inter-rater reliability.
The kappa statistics, use of "Rules" to solve conflicts, and exclusion of the starred subdivisions suggest as much.
This questions the appropriateness of our data extraction form, and the STROBE guidelines it is a based on, as a measure of reporting quality since it does not seem to accurately estimate reporting quality across coders.
This poor reliability may be because the STROBE guidelines were not designed as a measure of reporting quality.
The STROBE guidelines are reporting guidelines designed for authors to use to check their manuscript contains all the relevant information, while they are writing up.
The guidelines are not designed as an assessment of reporting by people other than the authors.
Reverse engineering the guidelines for a purpose they were not designed for may be why the inter-rater reliability is poor.
The appropriateness of the STROBE guidelines for secondary data analyses, such as those using the UK Biobank, is also questionable.
We used the STROBE guidelines to create our data extraction form because it was the most appropriate reporting guidelines available.
However, the STROBE guidelines did not necessarily capture the information we needed, leading to us excluding several STROBE items and including additional variables.
For example, the guidelines were written in 2007, therefore there is no question on whether or how authors reported analysis code.
We also excluded several items or subdivisions of items because they requested reporting of the same information or information not applicable to a seondary data analysis, specifically item 10, two subdivisions of item 6a, one subdivision of item 5, and one subdivision of item 8.
See the rule guidelines for further information on these duplicate and inapplicable variables (https://osf.io/hngcj/).

## Conclusions

Good reporting of statistical methods will aid replications of the main results. 
Comparing replication results to the original may be difficult given the poor reporting of unadjusted estimates.
The lack of shared code will also make replications more difficult.

# Funding Source

This review is being funded by the John Climax Benevolent Fund. 
The funder will support the conduct of the review by paying KD‚Äôs stipend. 
The funder had no input on any aspect of the project, such the protocol design, data collection, data analysis nor interpretation or publication of results.


# Conflicts of Interest
There are no conflicts of interest to report.

# Supplementary Material

```{r}
#Third, using Rayyan again, we classified studies as "traditional epidemiology", "Mendelian randomisation" and "Other", according to the #type of data they analysed.
#After we piloted these classifications on 20 studies, the classification criteria were:
#
#*	Traditional epidemiology ‚Äì studies investigating associations between exposures and health outcomes using the UK Biobank data alone. 
#*	Mendelian randomisation ‚Äì studies that conduct Mendelian randomisation analyses on UK Biobank data alone
#*	Other ‚Äì articles that do not meet the ‚ÄòTraditional epidemiology‚Äô or ‚ÄòMR‚Äô classification criteria described above or include analyses of #genetic or imaging data.
#
#BW and KD independently classified articles' abstracts.
#They examined full texts if classification was unclear from the abstract alone.
#They discussed any conflicts and resolved them by mutual consent if possible, if not resolved after discussion then RR assigned the #category.
#Articles could be allocated into more than one classification group.
#We then excluded all but the traditional epidemiology studies.
#The Mendialian randomisation studies were not relevant to this paper but we included it as a classification because the data may be used for one of our author's future projects.

```

Only including observational epidemiological studies is a major departure from the protocol in which we stated that studies would be "classified according to their data type" during data extraction but that all classifications would be included.
This was so we could analyse articles according to their appropriate STROBE extension, such as the strengthening the reporting of genetic association studies (STREGA) statement [@little2009].
Given that it would be too time-consuming to extract data from all studies in all included articles and to design multiple data extraction forms, we decided to extract data and assess the reporting quality of studies that could be assessed using the original STROBE guidelines only, i.e. traditional epidemiology studies. 

The final data extraction form combined the data items described as part of the "Data Extraction Form" and "Reporting Quality Assessment" in the protocol, but not all were kept.

## Supplementary Figure 1

*Supplementary Figure 1. Descriptive statistics for reporting quality of subdivisions of all STROBE items*
![](Rplot10.png)

## Supplementary Table 1

```{r, echo = F}
pander(kappa_sub, caption = "Supplementary Table 1. Kappa statistics for reporting quality of subdivisions of all STROBE items")
```

# References

@article{agha2014,
  title = {Randomised Controlled Trials in Plastic Surgery: A Systematic Review of Reporting Quality},
  shorttitle = {Randomised Controlled Trials in Plastic Surgery},
  author = {Agha, Riaz Ahmed and Camm, Christian F. and Doganay, Emre and Edison, Eric and Siddiqui, Muhammed R. S. and Orgill, Dennis P.},
  year = {2014},
  month = feb,
  volume = {37},
  pages = {55--62},
  issn = {0930-343X, 1435-0130},
  doi = {10.1007/s00238-013-0893-5},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\7ADZUUR3\\Agha et al. - 2014 - Randomised controlled trials in plastic surgery a.pdf},
  journal = {European Journal of Plastic Surgery},
  language = {en},
  number = {2}
}

@incollection{cevallos2014,
  title = {{{STROBE}} ({{STrengthening}} the {{Reporting}} of {{Observational}} Studies in {{Epidemiology}})},
  booktitle = {Guidelines for {{Reporting Health Research}}: {{A User}}'s {{Manual}}},
  author = {Cevallos, Myriam and Egger, Matthias},
  editor = {Moher, David and Altman, Douglas G. and Schulz, Kenneth F. and Simera, Iveta and Wager, Elizabeth},
  year = {2014},
  month = aug,
  pages = {169--179},
  publisher = {{John Wiley \& Sons, Ltd}},
  address = {{Oxford, UK}},
  doi = {10.1002/9781118715598.ch17},
  isbn = {978-1-118-71559-8 978-0-470-67044-6},
  language = {en}
}

@article{cook2011,
  title = {Method and Reporting Quality in Health Professions Education Research: {{A}} Systematic Review},
  author = {Cook, David A. and Levinson, Anthony J. and Garside, Sarah},
  year = {2011},
  month = mar,
  volume = {45},
  pages = {227--238},
  issn = {03080110},
  doi = {10.1111/j.1365-2923.2010.03890.x},
  abstract = {Studies evaluating reporting quality in health professions education (HPE) research have demonstrated deficiencies, but none have used comprehensive reporting standards. Additionally, the relationship between study methods and effect size (ES) in HPE research is unknown.},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\273UR2L9\\Cook, Levinson, Garside - 2011 - Method and reporting quality in health professions education research A systematic review.pdf},
  journal = {Medical Education},
  keywords = {empirical,reporting<sub>q</sub>uality,SR},
  number = {3},
  pmid = {21299598}
}

@article{hardwicke2018,
  ids = {hardwicke2018a,hardwickeDataAvailabilityReusability2018},
  title = {Data Availability, Reusability, and Analytic Reproducibility: Evaluating the Impact of a Mandatory Open Data Policy at the Journal {{{\emph{Cognition}}}}},
  shorttitle = {Data Availability, Reusability, and Analytic Reproducibility},
  author = {Hardwicke, Tom E. and Mathur, Maya B. and MacDonald, Kyle and Nilsonne, Gustav and Banks, George C. and Kidwell, Mallory C. and Hofelich Mohr, Alicia and Clayton, Elizabeth and Yoon, Erica J. and Henry Tessler, Michael and Lenne, Richie L. and Altman, Sara and Long, Bria and Frank, Michael C.},
  year = {2018},
  month = aug,
  volume = {5},
  pages = {180448},
  issn = {2054-5703},
  doi = {10.1098/rsos.180448},
  abstract = {Access to data is a critical feature of an efficient, progressive and ultimately self-correcting scientific ecosystem. But the extent to which in-principle benefits of data sharing are realized in practice is unclear. Crucially, it is largely unknown whether published findings can be reproduced by repeating reported analyses upon shared data (`analytic reproducibility'). To investigate this, we conducted an observational evaluation of a mandatory open data policy introduced at the journal               Cognition               . Interrupted time-series analyses indicated a substantial post-policy increase in data available statements (104/417, 25\% pre-policy to 136/174, 78\% post-policy), although not all data appeared reusable (23/104, 22\% pre-policy to 85/136, 62\%, post-policy). For 35 of the articles determined to have reusable data, we attempted to reproduce 1324 target values. Ultimately, 64 values could not be reproduced within a 10\% margin of error. For 22 articles all target values were reproduced, but 11 of these required author assistance. For 13 articles at least one value could not be reproduced despite author assistance. Importantly, there were no clear indications that original conclusions were seriously impacted. Mandatory open data policies can increase the frequency and quality of data sharing. However, suboptimal data curation, unclear analysis specification and reporting errors can impede analytic reproducibility, undermining the utility of data sharing and the credibility of scientific findings.},
  art_number = {[object Object]},
  author_keywords = {[object Object]},
  document_type = {[object Object]},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\C4M7R67J\\Hardwicke et al. - 2018 - Data availability, reusability, and analytic reproducibility Evaluating the impact of a mandatory open data(2).pdf;C\:\\Users\\kdrax\\Zotero\\storage\\KAMSLHCY\\Hardwicke et al. - 2018 - Data availability, reusability, and analytic reproducibility Evaluating the impact of a mandatory open data po.pdf;C\:\\Users\\kdrax\\Zotero\\storage\\VZGW2YWQ\\Hardwicke et al. - 2018 - Data availability, reusability, and analytic repro.pdf},
  journal = {Royal Society Open Science},
  keywords = {empirical,metaresearch,sharingₐnd<sub>r</sub>eanalyses,timeₛeries},
  language = {en},
  note = {cited By 7
\par
ZSCC: 0000050},
  number = {8},
  pmid = {30225032},
  source = {[object Object]}
}

@incollection{higgins2011,
  title = {Chapter 7: {{Selecting}} Studies and Collecting Data {{Key}} Points},
  booktitle = {Cochrane {{Handbook}} for {{Systematic Reviews}} of {{Interventions}}},
  author = {Higgins, Julian PT and Deeks, Jonathan J},
  editor = {Higgins, Julian P T and Deeks, J J},
  year = {2011},
  month = sep,
  publisher = {{John Wiley \& Sons, Ltd}},
  address = {{Chichester, UK}},
  doi = {10.1590/S1519-69842007000200012},
  abstract = {During the reproductive season Blue-black grassquit (Volatinia jacarina) males are found in clusters, wherein they exhibit a distinctive display that consists of repeated, vertical leaps while simultaneously producing a brief vocalization. The main objective of this study was to describe details of the species' reproductive behavior in a "Cerrado" area of central Brazil and compare these data with some studies carried out in other areas. The data obtained concerning different aspects of nesting, laying and hatching were generally similar to those obtained in previous studies in other areas. However, we found that the typical clutch size of two eggs per nest is lower, and egg and nestling mortality rates higher in our area than what has been reported elsewhere. Our results suggest that males differ in time expended with different activities according to their reproductive condition and also provide extensive parental care. We found that display execution rates peak in the early morning and in the late afternoon and are higher in the middle of the breeding season. We also found that there is an inverse relation between the height of the display leap and the height of the perch.},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\EVPQYMTU\\Higgins and Deeks - 2011 - Chapter 7 Selecting studies and collecting data K.pdf},
  isbn = {978-0-470-05796-4},
  pmid = {17876437}
}

@article{moher2016,
  title = {Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols ({{PRISMA}}-{{P}}) 2015 Statement},
  author = {Moher, David and Shamseer, Larissa and Clarke, Mike and Ghersi, Davina and Liberati, Alessandro and Petticrew, Mark and Shekelle, Paul and Stewart, Lesley A. and Estarli, Mireia and Barrera, Eliud S.Aguilar and {Mart{\'i}nez-Rodr{\'i}guez}, Rodrigo and Baladia, Eduard and Ag{\"u}ero, Samuel Duran and Camacho, Saby and Buhring, Kristian and {Herrero-L{\'o}pez}, Aitor and {Gil-Gonz{\'a}lez}, Diana Maria and Altman, Douglas G. and Booth, Alison and Chan, An Wen and Chang, Stephanie and Clifford, Tammy and Dickersin, Kay and Egger, Matthias and G{\o}tzsche, Peter C. and Grimshaw, Jeremy M. and Groves, Trish and Helfand, Mark and Higgins, Julian and Lasserson, Toby and Lau, Joseph and Lohr, Kathleen and McGowan, Jessie and Mulrow, Cynthia and Norton, Melissa and Page, Matthew and Sampson, Margaret and Sch{\"u}nemann, Holger and Simera, Iveta and Summerskill, William and Tetzlaff, Jennifer and Trikalinos, Thomas A. and Tovey, David and Turner, Lucy and Whitlock, Evelyn},
  year = {2016},
  month = dec,
  volume = {20},
  pages = {148--160},
  issn = {21731292},
  doi = {10.1186/2046-4053-4-1},
  abstract = {Systematic reviews should build on a protocol that describes the rationale, hypothesis, and planned methods of the review; few reviews report whether a protocol exists. Detailed, well-described protocols can facilitate the understanding and appraisal of the review methods, as well as the detection of modifications to methods and selective reporting in completed reviews. We describe the development of a reporting guideline, the Preferred Reporting Items for Systematic reviews and Meta-Analyses for Protocols 2015 (PRISMA-P 2015). PRISMA-P consists of a 17-item checklist intended to facilitate the preparation and reporting of a robust protocol for the systematic review. Funders and those commissioning reviews might consider mandating the use of the checklist to facilitate the submission of relevant protocol information in funding applications. Similarly, peer reviewers and editors can use the guidance to gauge the completeness and transparency of a systematic review protocol submitted for publication in a journal or other medium.},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\6IRHLJF5\\Moher et al. - 2016 - Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015 statement.pdf},
  journal = {Revista Espanola de Nutricion Humana y Dietetica},
  keywords = {non-empirical,reporting<sub>c</sub>hecklist},
  number = {2},
  pmid = {25554246}
}

@article{naudet2018,
  title = {Data Sharing and Reanalysis of Randomized Controlled Trials in Leading Biomedical Journals with a Full Data Sharing Policy: Survey of Studies Published in {{{\emph{The BMJ}}}} and {{{\emph{PLOS Medicine}}}}},
  shorttitle = {Data Sharing and Reanalysis of Randomized Controlled Trials in Leading Biomedical Journals with a Full Data Sharing Policy},
  author = {Naudet, Florian and Sakarovitch, Charlotte and Janiaud, Perrine and Cristea, Ioana and Fanelli, Daniele and Moher, David and Ioannidis, John P A},
  year = {2018},
  month = feb,
  pages = {k400},
  issn = {0959-8138, 1756-1833},
  doi = {10.1136/bmj.k400},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\GZXECPJF\\Naudet et al. - 2018 - Data sharing and reanalysis of randomized controll.pdf},
  journal = {BMJ},
  keywords = {empirical,sharingₐnd<sub>r</sub>eanalyses},
  language = {en},
  pmid = {29440066}
}

@article{ouzzani2016,
  title = {Rayyan-a Web and Mobile App for Systematic Reviews},
  author = {Ouzzani, Mourad and Hammady, Hossam and Fedorowicz, Zbys and Elmagarmid, Ahmed},
  year = {2016},
  month = dec,
  volume = {5},
  pages = {210},
  issn = {20464053},
  doi = {10.1186/s13643-016-0384-4},
  abstract = {Synthesis of multiple randomized controlled trials (RCTs) in a systematic review can summarize the effects of individual outcomes and provide numerical answers about the effectiveness of interventions. Filtering of searches is time consuming, and no single method fulfills the principal requirements of speed with accuracy. Automation of systematic reviews is driven by a necessity to expedite the availability of current best evidence for policy and clinical decision-making. We developed Rayyan (\$\textbackslash backslash\$n http://rayyan.qcri.org\$\textbackslash backslash\$n \$\textbackslash backslash\$n ), a free web and mobile app, that helps expedite the initial screening of abstracts and titles using a process of semi-automation while incorporating a high level of usability. For the beta testing phase, we used two published Cochrane reviews in which included studies had been selected manually. Their searches, with 1030 records and 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan's users and collected feedback through a built-in feature. Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The ``taster'' review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The ``suggestions'' and ``hints,'' based on the ``prediction model,'' appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40\% average time savings when using Rayyan compared to others tools, with 34\% of the respondents reporting more than 50\% time savings. In addition, around 75\% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users. Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\9R8TLNJ8\\Ouzzani et al. - 2016 - Rayyan-a web and mobile app for systematic reviews.pdf},
  journal = {Systematic Reviews},
  keywords = {rayyan,software},
  number = {1},
  pmid = {27919275}
}

@article{plint2006,
  title = {Does the {{CONSORT}} Checklist Improve the Quality of Reports Of ...},
  author = {Plint, Amy and Moher, David and Morrison, Andra and Schulz, Kenneth and Altman, Douglas and Hill, Catherine and Gaboury, Isabelle},
  year = {2006},
  month = sep,
  volume = {185},
  pages = {263},
  issn = {0025-729X},
  doi = {10.5694/J.1326-5377.2006.TB00557.X},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\4UW3ILJ5\\Plint et al. - 2006 - Does the CONSORT checklist improve the quality of reports of .pdf},
  journal = {Medical Journal of Australia},
  keywords = {CONSORT,efficacy<sub>r</sub>eporting<sub>c</sub>hecklists,empirical,reporting<sub>q</sub>uality},
  number = {5},
  pmid = {16948622}
}

@article{shamseer2015,
  title = {Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols (Prisma-p) 2015: {{Elaboration}} and Explanation},
  author = {Shamseer, Larissa and Moher, David and Clarke, Mike and Ghersi, Davina and Liberati, Alessandro and Petticrew, Mark and Shekelle, Paul and Stewart, Lesley A. and Altman, Douglas G. and Booth, Alison and Chan, An Wen and Chang, Stephanie and Clifford, Tammy and Dickersin, Kay and Egger, Matthias and G{\o}tzsche, Peter C. and Grimshaw, Jeremy M. and Groves, Trish and Helfand, Mark and Higgins, Julian and Lasserson, Toby and Lau, Joseph and Lohr, Kathleen and McGowan, Jessie and Mulrow, Cynthia and Norton, Melissa and Page, Matthew and Sampson, Margaret and Sch{\"u}nemann, Holger and Simera, Iveta and Summerskill, William and Tetzlaff, Jennifer and Trikalinos, Thomas A. and Tovey, David and Turner, Lucy and Whitlock, Evelyn},
  year = {2015},
  month = jan,
  volume = {349},
  pages = {g7647},
  issn = {17561833},
  doi = {10.1136/bmj.g7647},
  abstract = {Protocols of systematic reviews and meta-analyses allow for planning and documentation of review methods, act as a guard against arbitrary decision making during review conduct, enable readers to assess for the presence of selective reporting against completed reviews, and, when made publicly available, reduce duplication of efforts and potentially prompt collaboration. Evidence documenting the existence of selective reporting and excessive duplication of reviews on the same or similar topics is accumulating and many calls have been made in support of the documentation and public availability of review protocols. Several efforts have emerged in recent years to rectify these problems, including development of an international register for prospective reviews (PROSPERO) and launch of the first open access journal dedicated to the exclusive publication of systematic review products, including protocols (BioMed Central's Systematic Reviews). Furthering these efforts and building on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-analyses) guidelines, an international group of experts has created a guideline to improve the transparency, accuracy, completeness, and frequency of documented systematic review and meta-analysis protocols\textendash PRISMA-P (for protocols) 2015. The PRISMA-P checklist contains 17 items considered to be essential and minimum components of a systematic review or meta-analysis protocol.This PRISMA-P 2015 Explanation and Elaboration paper provides readers with a full understanding of and evidence about the necessity of each item as well as a model example from an existing published protocol. This paper should be read together with the PRISMA-P 2015 statement. Systematic review authors and assessors are strongly encouraged to make use of PRISMA-P when drafting and appraising review protocols.},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\RPU3VVK9\\Shamseer et al. - 2015 - Preferred reporting items for systematic review and meta-analysis protocols (prisma-p) 2015 Elaboration and exp.pdf},
  journal = {BMJ (Online)},
  keywords = {non-empirical,reporting<sub>c</sub>hecklist},
  number = {1},
  pmid = {25555855}
}

@techreport{ukbiobankcoordinatingcentre2007,
  title = {{{UK Biobank}}: {{Protocol}} for a Large-Scale Prospective Epidemiological Resource {{UK Biobank Coordinating Centre Stockport}}},
  author = {{UK Biobank Coordinating Centre}},
  year = {2007},
  pages = {1--112},
  abstract = {Fujii and colleagues define 'subacute' kidney injury (s-AKI) as AKI that takes \textbackslash textgreater7 days to develop, timed from admission or lowest creatinine measurement after admission. Although s-AKI is unlikely to be a distinct syndrome from AKI, the association with increased mortality highlights the need to monitor patient creatinine levels.},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\7K7N6MDK\\UK Biobank Coordinating Centre - 2007 - UK Biobank Protocol for a large-scale prospective epidemiological resource UK Biobank Coordinati.pdf},
  keywords = {uk biobank protocol},
  number = {March}
}

@techreport{ukbiobankcoordinatingcentre2011,
  title = {Access {{Procedures}}: {{Application}} and Review Procedures for Access to the {{UK Biobank Resource}}},
  author = {{UK Biobank Coordinating Centre}},
  year = {2011},
  pages = {1--36}
}

@article{vasilevsky2017,
  title = {Reproducible and Reusable Research: Are Journal Data Sharing Policies Meeting the Mark?},
  shorttitle = {Reproducible and Reusable Research},
  author = {Vasilevsky, Nicole A. and Minnier, Jessica and Haendel, Melissa A. and Champieux, Robin E.},
  year = {2017},
  month = apr,
  volume = {5},
  pages = {e3208},
  issn = {2167-8359},
  doi = {10.7717/peerj.3208},
  abstract = {Background               There is wide agreement in the biomedical research community that research data sharing is a primary ingredient for ensuring that science is more transparent and reproducible. Publishers could play an important role in facilitating and enforcing data sharing; however, many journals have not yet implemented data sharing policies and the requirements vary widely across journals. This study set out to analyze the pervasiveness and quality of data sharing policies in the biomedical literature.                                         Methods               The online author's instructions and editorial policies for 318 biomedical journals were manually reviewed to analyze the journal's data sharing requirements and characteristics. The data sharing policies were ranked using a rubric to determine if data sharing was required, recommended, required only for omics data, or not addressed at all. The data sharing method and licensing recommendations were examined, as well any mention of reproducibility or similar concepts. The data was analyzed for patterns relating to publishing volume, Journal Impact Factor, and the publishing model (open access or subscription) of each journal.                                         Results               A total of 11.9\% of journals analyzed explicitly stated that data sharing was required as a condition of publication. A total of 9.1\% of journals required data sharing, but did not state that it would affect publication decisions. 23.3\% of journals had a statement encouraging authors to share their data but did not require it. A total of 9.1\% of journals mentioned data sharing indirectly, and only 14.8\% addressed protein, proteomic, and/or genomic data sharing. There was no mention of data sharing in 31.8\% of journals. Impact factors were significantly higher for journals with the strongest data sharing policies compared to all other data sharing criteria. Open access journals were not more likely to require data sharing than subscription journals.                                         Discussion               Our study confirmed earlier investigations which observed that only a minority of biomedical journals require data sharing, and a significant association between higher Impact Factors and journals with a data sharing requirement. Moreover, while 65.7\% of the journals in our study that required data sharing addressed the concept of reproducibility, as with earlier investigations, we found that most data sharing policies did not provide specific guidance on the practices that ensure data is maximally available and reusable.},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\298PJZGI\\Vasilevsky et al. - 2017 - Reproducible and reusable research are journal da.pdf},
  journal = {PeerJ},
  language = {en}
}

@techreport{worldwidewebfoundation2018,
  title = {Open {{Data Barometer}} - {{Leaders Edition}}},
  author = {{World Wide Web Foundation}},
  year = {2018},
  address = {{Washington DC}},
  institution = {{World Wide Web Foundation}},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\INXYNP4B\\World Wide Web Foundation - 2018 - Open data barometer. Leaders edition. From promise.pdf}
}

@article{drax2019,
  title = {{{UK Biobank Study}} - {{Systematic Review}}},
  author = {Drax, Katie and Richmond, Rebecca and Woolf, Benjamin and Smith, George and Munafo, Marcus},
  date = {2019},
  publisher = {{Open Science Framework}},
  doi = {10.17605/OSF.IO/SF5VJ},
  url = {https://osf.io/sf5vj/},
  urldate = {2021-08-11},
  abstract = {Systematic review of the reporting quality of studies using the UK Biobank}
}

@article{little2009,
  title = {{{STrengthening}} the {{REporting}} of Genetic Association Studies ({{STREGA}})- {{An}} Extension of the {{STROBE}} Statement},
  author = {Little, Julian and Higgins, Julian P.T. and Ioannidis, John P.A. and Moher, David and Gagnon, France and Von Elm, Erik and Khoury, Muin J. and Cohen, Barbara and Davey-Smith, George and Grimshaw, Jeremy and Scheet, Paul and Gwinn, Marta and Williamson, Robin E. and Zou, Guang Yong and Hutchings, Kim and Johnson, Candice Y. and Tait, Valerie and Wiens, Miriam and Golding, Jean and Van Duijn, Cornelia and McLaughlin, John and Paterson, Andrew and Wells, George and Fortier, Isabel and Freedman, Matthew and Zecevic, Maja and King, Richard and Infante-Rivard, Claire and Stewart, Alex and Birkett, Nick},
  date = {2009-02},
  journaltitle = {Genetic Epidemiology},
  volume = {33},
  number = {7},
  eprint = {19189221},
  eprinttype = {pmid},
  pages = {581--598},
  issn = {07410395},
  doi = {10.1002/gepi.20410},
  url = {https://dx.plos.org/10.1371/journal.pmed.1000022},
  abstract = {Making sense of rapidly evolving evidence on genetic associations is crucial to making genuine advances in human genomics and the eventual integration of this information in the practice of medicine and public health. Assessment of the strengths and weaknesses of this evidence, and hence, the ability to synthesize it, has been limited by inadequate reporting of results. The STrengthening the REporting of Genetic Association (STREGA) studies initiative builds on the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement and provides additions to 12 of the 22 items on the STROBE checklist. The additions concern population stratification, genotyping errors, modeling haplotype variation, Hardy-Weinberg equilibrium, replication, selection of participants, rationale for choice of genes and variants, treatment effects in studying quantitative traits, statistical methods, relatedness, reporting of descriptive and outcome data, and the volume of data issues that are important to consider in genetic association studies. The STREGA recommendations do not prescribe or dictate how a genetic association study should be designed, but seek to enhance the transparency of its reporting, regardless of choices made during design, conduct, or analysis. © 2009 Elsevier Inc. All rights reserved.},
  keywords = {non-empirical,reporting_checklist},
  file = {C\:\\Users\\kdrax\\Zotero\\storage\\L5TG3964\\Little et al. - 2009 - STrengthening the REporting of genetic association studies (STREGA)- An extension of the STROBE statement.pdf}
}